{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Done\n",
      "Loading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import shutil, os, csv, itertools, glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import configs as cfgs\n",
    "cuda = cfgs.USE_CUDA\n",
    "\n",
    "from model import CAN\n",
    "from dataloader import train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(output, target):\n",
    "    # takes in two tensors to compute accuracy\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    return correct, target.size(0)\n",
    "\n",
    "def run_trainer(model_path, model, train_loader, test_loader, get_acc, resume, num_epoch):\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    def save_checkpoint(state, is_best, filename=model_path+'checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, model_path+'model_best.pth.tar')\n",
    "    def get_last_checkpoint(model_path):\n",
    "        fs = sorted([f for f in os.listdir(model_path) if 'Epoch' in f], key=lambda k: int(k.split()[1]))\n",
    "        return model_path+fs[-1] if len(fs) > 0 else None\n",
    "    \n",
    "    start_epoch = 0\n",
    "    best_res = 0\n",
    "    resume_state = get_last_checkpoint(model_path) if resume else None\n",
    "    if resume_state and os.path.isfile(resume_state):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume_state))\n",
    "        checkpoint = torch.load(resume_state)\n",
    "        start_epoch = checkpoint['epoch']+1\n",
    "        best_res = checkpoint['val_acc']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), **cfgs.OPT_PARAM)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resume_state, checkpoint['epoch']))\n",
    "    else:\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), **cfgs.OPT_PARAM)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5) # optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5)\n",
    "\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        total, total_correct = 0., 0.\n",
    "        for batch_idx, (img_feats, question, answer) in enumerate(train_loader):\n",
    "            img_feats, question, answer = Variable(img_feats.float()), Variable(question.float()), Variable(answer.long())\n",
    "            if cuda:\n",
    "                img_feats, question, answer = img_feats.cuda(), question.cuda(), answer.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img_feats, question)\n",
    "            loss = criterion(output, answer)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct, num_instance = get_acc(output, answer)\n",
    "            total_correct += correct\n",
    "            total += num_instance\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Acc: {:.2f}%/{:.2f}%'.format(\n",
    "                    epoch, batch_idx * cfgs.BATCH_SIZE, len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0],\n",
    "                    100. * correct / num_instance, 100. * total_correct / total ))\n",
    "        \n",
    "        return 100. * total_correct / total\n",
    "\n",
    "    def test():\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total, total_correct = 0., 0.\n",
    "        for img_feats, question, answer in test_loader:\n",
    "            img_feats, question, answer = Variable(img_feats.float()), Variable(question.float()), Variable(answer.long())\n",
    "            if cuda:\n",
    "                img_feats, question, answer = img_feats.cuda(), question.cuda(), answer.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img_feats, question)\n",
    "            test_loss += criterion(output, answer).data[0] # sum up batch loss\n",
    "            \n",
    "            correct, num_instance = get_acc(output, answer)\n",
    "            total_correct += correct\n",
    "            total += num_instance\n",
    "\n",
    "        test_acc = 100. * total_correct / total\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, total_correct, total,\n",
    "            test_acc))\n",
    "\n",
    "        return test_acc\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, num_epoch):\n",
    "        is_best = False\n",
    "\n",
    "        train_acc = train(epoch)\n",
    "        val_acc = test()\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "        if val_acc > best_res:\n",
    "            best_res = val_acc\n",
    "            is_best = True\n",
    "\n",
    "        save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.cpu().state_dict(),\n",
    "                'train_acc':train_acc,\n",
    "                'val_acc': val_acc,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best,\n",
    "            model_path+\"Epoch %d Acc %.4f.pt\"%(epoch, val_acc))\n",
    "\n",
    "        if cuda:\n",
    "            model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/699989 (0%)]\tLoss: 3.332168 Acc: 1.56%/1.56%\n",
      "Train Epoch: 0 [640/699989 (0%)]\tLoss: 3.333085 Acc: 1.56%/2.56%\n",
      "Train Epoch: 0 [1280/699989 (0%)]\tLoss: 3.332601 Acc: 3.12%/2.75%\n",
      "Train Epoch: 0 [1920/699989 (0%)]\tLoss: 3.332855 Acc: 4.69%/2.47%\n",
      "Train Epoch: 0 [2560/699989 (0%)]\tLoss: 3.332503 Acc: 3.12%/2.32%\n",
      "Train Epoch: 0 [3200/699989 (0%)]\tLoss: 3.332510 Acc: 6.25%/2.51%\n",
      "Train Epoch: 0 [3840/699989 (1%)]\tLoss: 3.332615 Acc: 3.12%/2.28%\n",
      "Train Epoch: 0 [4480/699989 (1%)]\tLoss: 3.332594 Acc: 1.56%/2.22%\n",
      "Train Epoch: 0 [5120/699989 (1%)]\tLoss: 3.332317 Acc: 3.12%/2.22%\n",
      "Train Epoch: 0 [5760/699989 (1%)]\tLoss: 3.332532 Acc: 4.69%/2.21%\n",
      "Train Epoch: 0 [6400/699989 (1%)]\tLoss: 3.332451 Acc: 0.00%/2.13%\n",
      "Train Epoch: 0 [7040/699989 (1%)]\tLoss: 3.332325 Acc: 4.69%/2.21%\n",
      "Train Epoch: 0 [7680/699989 (1%)]\tLoss: 3.332519 Acc: 3.12%/2.21%\n",
      "Train Epoch: 0 [8320/699989 (1%)]\tLoss: 3.332288 Acc: 1.56%/2.19%\n",
      "Train Epoch: 0 [8960/699989 (1%)]\tLoss: 3.332428 Acc: 3.12%/2.16%\n",
      "Train Epoch: 0 [9600/699989 (1%)]\tLoss: 3.332369 Acc: 0.00%/2.18%\n",
      "Train Epoch: 0 [10240/699989 (1%)]\tLoss: 3.332456 Acc: 3.12%/2.17%\n",
      "Train Epoch: 0 [10880/699989 (2%)]\tLoss: 3.332374 Acc: 3.12%/2.23%\n",
      "Train Epoch: 0 [11520/699989 (2%)]\tLoss: 3.332380 Acc: 1.56%/2.20%\n",
      "Train Epoch: 0 [12160/699989 (2%)]\tLoss: 3.332295 Acc: 1.56%/2.26%\n",
      "Train Epoch: 0 [12800/699989 (2%)]\tLoss: 3.332276 Acc: 3.12%/2.26%\n",
      "Train Epoch: 0 [13440/699989 (2%)]\tLoss: 3.332303 Acc: 1.56%/2.24%\n",
      "Train Epoch: 0 [14080/699989 (2%)]\tLoss: 3.332334 Acc: 1.56%/2.23%\n",
      "Train Epoch: 0 [14720/699989 (2%)]\tLoss: 3.332262 Acc: 4.69%/2.22%\n",
      "Train Epoch: 0 [15360/699989 (2%)]\tLoss: 3.332242 Acc: 3.12%/2.24%\n",
      "Train Epoch: 0 [16000/699989 (2%)]\tLoss: 3.332291 Acc: 0.00%/2.27%\n",
      "Train Epoch: 0 [16640/699989 (2%)]\tLoss: 3.332263 Acc: 3.12%/2.27%\n",
      "Train Epoch: 0 [17280/699989 (2%)]\tLoss: 3.332275 Acc: 4.69%/2.24%\n",
      "Train Epoch: 0 [17920/699989 (3%)]\tLoss: 3.332295 Acc: 0.00%/2.24%\n",
      "Train Epoch: 0 [18560/699989 (3%)]\tLoss: 3.332233 Acc: 1.56%/2.21%\n",
      "Train Epoch: 0 [19200/699989 (3%)]\tLoss: 3.332148 Acc: 0.00%/2.21%\n",
      "Train Epoch: 0 [19840/699989 (3%)]\tLoss: 3.332288 Acc: 0.00%/2.16%\n",
      "Train Epoch: 0 [20480/699989 (3%)]\tLoss: 3.332226 Acc: 1.56%/2.16%\n",
      "Train Epoch: 0 [21120/699989 (3%)]\tLoss: 3.332246 Acc: 1.56%/2.14%\n",
      "Train Epoch: 0 [21760/699989 (3%)]\tLoss: 3.332182 Acc: 1.56%/2.12%\n",
      "Train Epoch: 0 [22400/699989 (3%)]\tLoss: 3.332216 Acc: 1.56%/2.11%\n",
      "Train Epoch: 0 [23040/699989 (3%)]\tLoss: 3.332210 Acc: 0.00%/2.08%\n",
      "Train Epoch: 0 [23680/699989 (3%)]\tLoss: 3.332196 Acc: 0.00%/2.06%\n",
      "Train Epoch: 0 [24320/699989 (3%)]\tLoss: 3.332191 Acc: 3.12%/2.05%\n",
      "Train Epoch: 0 [24960/699989 (4%)]\tLoss: 3.332185 Acc: 1.56%/2.02%\n",
      "Train Epoch: 0 [25600/699989 (4%)]\tLoss: 3.332180 Acc: 1.56%/2.00%\n",
      "Train Epoch: 0 [26240/699989 (4%)]\tLoss: 3.332172 Acc: 1.56%/1.98%\n",
      "Train Epoch: 0 [26880/699989 (4%)]\tLoss: 3.332159 Acc: 3.12%/1.96%\n",
      "Train Epoch: 0 [27520/699989 (4%)]\tLoss: 3.332173 Acc: 1.56%/1.94%\n",
      "Train Epoch: 0 [28160/699989 (4%)]\tLoss: 3.332153 Acc: 1.56%/1.91%\n",
      "Train Epoch: 0 [28800/699989 (4%)]\tLoss: 3.332140 Acc: 3.12%/1.90%\n",
      "Train Epoch: 0 [29440/699989 (4%)]\tLoss: 3.332149 Acc: 1.56%/1.88%\n",
      "Train Epoch: 0 [30080/699989 (4%)]\tLoss: 3.332157 Acc: 1.56%/1.86%\n",
      "Train Epoch: 0 [30720/699989 (4%)]\tLoss: 3.332138 Acc: 14.06%/1.97%\n",
      "Train Epoch: 0 [31360/699989 (4%)]\tLoss: 3.332169 Acc: 26.56%/2.23%\n",
      "Train Epoch: 0 [32000/699989 (5%)]\tLoss: 3.332156 Acc: 14.06%/2.58%\n",
      "Train Epoch: 0 [32640/699989 (5%)]\tLoss: 3.332168 Acc: 15.62%/2.90%\n",
      "Train Epoch: 0 [33280/699989 (5%)]\tLoss: 3.332164 Acc: 14.06%/3.27%\n",
      "Train Epoch: 0 [33920/699989 (5%)]\tLoss: 3.332147 Acc: 23.44%/3.61%\n"
     ]
    }
   ],
   "source": [
    "model = CAN(**cfgs.NET_PARAM)\n",
    "run_trainer(\n",
    "    model_path = './ckpt/', \n",
    "    model = model, \n",
    "    train_loader = train_loader, \n",
    "    test_loader = val_loader, \n",
    "    get_acc = get_acc, \n",
    "    resume = False, \n",
    "    num_epoch = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
